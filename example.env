# The environment setting.
# Use 'development' for local development, and 'production' in production.
ENVIRONMENT=development

# The host port that will be mapped to the development server (only used in development).
WEB_DEV_PORT=8000

# The host ports that will be mapped to the production server (only used in production).
WEB_HTTP_PORT=80
WEB_HTTPS_PORT=443

# Django debug settings (only used in development).
FORCE_DEBUG_TOOLBAR=true
REMOTE_DEBUGGING_ENABLED=false
REMOTE_DEBUGGING_PORT=5678

# The Django secret key used for cryptographic signing.
# IMPORTANT: Use a unique and secure key in production!
DJANGO_SECRET_KEY="your_django_secret_key_here"

# The Postgres database password (only used in production).
POSTGRES_PASSWORD="your_postgres_password_here"

# Miscellaneous Django security settings.
DJANGO_ALLOWED_HOSTS=localhost,127.0.0.1
DJANGO_CSRF_TRUSTED_ORIGINS=
DJANGO_INTERNAL_IPS=127.0.0.1

# The salt that is used for hashing tokens in the token authentication app.
# Cave, changing the salt after some tokens were already generated makes them all invalid!
TOKEN_AUTHENTICATION_SALT="your_token_authentication_salt_here"

# Email configuration.
# The email address that is used for sending emails to the users and critical errors
# to the admins. The smtp server is only used in production. In development the emails
# are just logged to the console.
DJANGO_SERVER_EMAIL="server@example-project.example"
DJANGO_EMAIL_URL="smtp://localhost:25"

# The Django server admins that will receive critical error notifications.
# Also used by django-registration-redux to send account approval emails to.
DJANGO_ADMIN_EMAIL="admin@radis.example"
DJANGO_ADMIN_FULL_NAME="RADIS Admin"

# A support Email address that is presented to the users where they can get support.
SUPPORT_EMAIL="support@radis.example"

# A superuser that will have access to the Django admin interface.
# Optionally with a provided auth token for the API.
SUPERUSER_USERNAME="superuser"
SUPERUSER_EMAIL="superuser@radis.example"
SUPERUSER_PASSWORD="your_superuser_password_here"
SUPERUSER_AUTH_TOKEN="your_superuser_auth_token_here"

# Location of the backup folder.
BACKUP_DIR="/tmp/backups"

# Site information that is stored initially in the database.
SITE_NAME="RADIS"
SITE_DOMAIN=localhost
SITE_USES_HTTPS=false

# Settings for SSL encrpytion (only used in production).
# SSL_HOSTNAME and SSL_IP_ADDRESSES are used to generate self-signed certificates
# with 'invoke generate-certificate-files', but you can also provide both files
# on your own.
SSL_HOSTNAME=localhost
SSL_IP_ADDRESSES=127.0.0.1
SSL_CERT_FILE="./cert.pem"
SSL_KEY_FILE="./key.pem"
SSL_CHAIN_FILE="./chain.pem"

# The timezone that the web interface uses.
USER_TIME_ZONE="Europe/Berlin"

# The language of the example reports that will be seeded to the development database.
# Possible values are 'en' or 'de'.
EXAMPLE_REPORTS_LANGUAGE=en

# Should the GPU (if one exists) be used in development for LLM inference
# Only used in development as the GPU is a must in production.
GPU_INFERENCE_ENABLED=false

# The LLM to use for inference.
# Development grade models:
LLM_MODEL_URL="https://huggingface.co/unsloth/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q4_K_M.gguf" # 105MB
# LLM_MODEL_URL="https://huggingface.co/unsloth/SmolLM2-360M-Instruct-GGUF/resolve/main/SmolLM2-360M-Instruct-Q4_K_M.gguf" # 271MB
# LLM_MODEL_URL="https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat-GGUF/resolve/main/qwen1_5-0_5b-chat-q2_k.gguf" # 298MB
# LLM_MODEL_URL="https://huggingface.co/Qwen/Qwen2-0.5B-Instruct-GGUF/resolve/main/qwen2-0_5b-instruct-q2_k.gguf" # 339MB
# LLM_MODEL_URL="https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF/resolve/main/qwen2.5-0.5b-instruct-q2_k.gguf" # 415MB
# Production grade models:
# LLM_MODEL_URL="https://huggingface.co/Qwen/Qwen2.5-32B-Instruct-GGUF/resolve/main/qwen2.5-32b-instruct-q8_0-00001-of-00009.gguf" # ~35GB
# LLM_MODEL_URL="https://huggingface.co/Qwen/Qwen2.5-72B-Instruct-GGUF/resolve/main/qwen2.5-72b-instruct-q4_0-00001-of-00011.gguf" # ~41GB
# LLM_MODEL_URL="https://huggingface.co/redponike/SauerkrautLM-Qwen-32b-GGUF/resolve/main/SauerkrautLM-Qwen-32b-Q5_K_M.gguf" # 23.1GB
# LLM_MODEL_URL="https://huggingface.co/bartowski/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct-Q4_K_M.gguf" # 42.5GB

# OpenAI API key. Only used to generate example reports with 'invoke generate-example-reports'.
OPENAI_API_KEY="your_openai_api_key_here"

# Docker swarm mode does not respect the Docker Proxy client configuration
# (see https://docs.docker.com/network/proxy/#configure-the-docker-client),
# but we can set those environment variables manually.
# Malke sure to use .local in NO_PROXY as otherwise the communication with
# the other services will not work.
# HTTP_PROXY="http://user:pass@myproxy.net:8080"
# HTTPS_PROXY="http://user:pass@myproxy.net:8080"
# NO_PROXY="localhost,.local"
