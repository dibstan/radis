x-app: &default-app
  image: radis_prod:latest
  env_file:
    - ../.env.prod
  environment:
    ENABLE_REMOTE_DEBUGGING: 0
    DJANGO_SETTINGS_MODULE: "radis.settings.production"
    SSL_CERT_FILE: "/var/www/radis/ssl/cert.pem"
    SSL_KEY_FILE: "/var/www/radis/ssl/key.pem"

x-deploy: &deploy
  replicas: 1
  restart_policy:
    condition: on-failure
    max_attempts: 3

services:
  # We can't use those manage commands inside the web container in production because
  # the web service may have multiple replicas. So we make sure to only run them once
  # and wait for it to be finished by the web service containers.
  init:
    <<: *default-app
    hostname: init.local
    command: >
      bash -c "
        wait-for-it -s postgres.local:5432 -t 120 && 
        ./manage.py migrate &&
        ./manage.py collectstatic --no-input &&
        ./manage.py create_admin &&
        ./manage.py generate_cert &&
        wait-for-it -s opensearch-node1.local:9200 -t 60 &&
        ./manage.py opensearch --mappings prod &&
        # wait-for-it -s vespa.local:19071 -t 60 &&
        # ./manage.py vespa --generate --deploy &&
        ./manage.py ok_server --host 0.0.0.0 --port 8000
      "
    deploy:
      <<: *deploy

  web:
    <<: *default-app
    build:
      target: production
    ports:
      - "${RADIS_HTTP_PORT:-80}:80"
      - "${RADIS_HTTPS_PORT:-443}:443"
    command: >
      bash -c "
        wait-for-it -s init.local:8000 -t 300 &&
        echo 'Starting web server ...'
        daphne -b 0.0.0.0 -p 80 -e ssl:443:privateKey=/var/www/radis/ssl/key.pem:certKey=/var/www/radis/ssl/cert.pem radis.asgi:application
      "
    deploy:
      <<: *deploy
      replicas: 3

  worker_default:
    <<: *default-app
    command: ./manage.py celery_worker -Q default_queue
    deploy:
      <<: *deploy

  worker_vespa:
    <<: *default-app
    command: ./manage.py celery_worker -c 1 -Q vespa_queue
    deploy:
      <<: *deploy

  worker_llm:
    <<: *default-app
    command: ./manage.py celery_worker -c 1 -Q llm_queue
    deploy:
      <<: *deploy

  celery_beat:
    <<: *default-app
    command: ./manage.py celery_beat
    deploy:
      <<: *deploy

  flower:
    <<: *default-app
    deploy:
      <<: *deploy

  llamacpp_gpu:
    image: ghcr.io/ggerganov/llama.cpp:server-cuda
    hostname: llamacpp.local
    environment:
      LLAMA_CACHE: "/models"
    env_file:
      - ../.env.prod
    ports:
      - 9610:8080
    volumes:
      - models_data:/models
    entrypoint: "/bin/bash -c '/llama-server -mu $${LLM_MODEL_URL} -ngl 50 -cb -c 4096 --host 0.0.0.0 --port 8080'"
    deploy:
      # <<: *deploy
      resources:
        reservations:
          # https://gist.github.com/medihack/6a6d24dc6376939e1919f32409c2119f
          generic_resources:
            - discrete_resource_spec:
                kind: "gpu"
                value: 1

  postgres:
    env_file:
      - ../.env.prod
    deploy:
      <<: *deploy

  opensearch_node1:
    image: opensearchproject/opensearch:2
    hostname: opensearch-node1.local
    environment:
      discovery.type: single-node # https://github.com/gitpod-io/gitpod/issues/8399
      bootstrap.memory_lock: "true"
      OPENSEARCH_JAVA_OPTS: "-Xms4g -Xmx4g"
      DISABLE_SECURITY_PLUGIN: "true"
    env_file:
      - ../.env.prod
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - opensearch_data1:/usr/share/opensearch/data
    ports:
      - 9200:9200 # REST API
      - 9600:9600 # Performance Analyzer
    deploy:
      <<: *deploy

  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2
    ports:
      - 5601:5601
    environment:
      OPENSEARCH_HOSTS: '["https://opensearch-node1.local:9200"]'
    deploy:
      <<: *deploy

  vespa:
    image: vespaengine/vespa:8
    hostname: vespa.local
    healthcheck:
      test: curl http://localhost:19071/state/v1/health
      timeout: 10s
      retries: 3
      start_period: 40s
    volumes:
      - vespa_data:/opt/vespa/var
      - vespa_logs:/opt/vespa/logs
    ports:
      - 9620:8080
    deploy:
      replicas: 0

  rabbit:
    deploy:
      <<: *deploy

  redis:
    deploy:
      <<: *deploy

volumes:
  models_data:
  opensearch_data1:
  vespa_data:
  vespa_logs:
